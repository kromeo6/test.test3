apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "my-awesome-model"
  namespace: "kubeflow-user-example-com"
  annotations:
    serving.kserve.io/s3-endpoint: "http://minio-service.kubeflow:9000"  # Replace with your MinIO endpoint
spec:
  predictor:
    serviceAccountName: "sa-minio-kserve"
    sklearn: # You may need to adjust this section for other model types
      storageUri: "s3://mlpipeline/v2/artifacts/my-pipeline/f82af73b-94a7-4280-a80b-50f4501e4786/model-training/0be473c1-7b28-43e8-8f11-70ab82e674d7/model_trained/model.pkl"  # Path to your model in MinIO
      resources:
        limits:
          cpu: 100m
          memory: 2Gi
        requests:
          cpu: 100m
          memory: 2Gi
